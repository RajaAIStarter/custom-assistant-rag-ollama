{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Note:** The current dataset is synthetic and quite limited. The pipeline demonstrates a basic approach to data processing and retrieval. For larger or different datasets, consider using specialized models and customized retrieval techniques.\n"
      ],
      "metadata": {
        "id": "HwJc7q4p8WS2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "INSTALL NECESSARY DEPENDENCIES"
      ],
      "metadata": {
        "id": "igXMHmkAzD4y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain pdfplumber transformers langchain-community"
      ],
      "metadata": {
        "id": "HSb1nz_cGU-p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import re\n",
        "from google.colab import files\n",
        "from langchain.document_loaders import PDFPlumberLoader\n",
        "from langchain.docstore.document import Document\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain_community.vectorstores.inmemory import InMemoryVectorStore\n",
        "import pickle"
      ],
      "metadata": {
        "id": "AhR1e1JKGEXT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "LOAD THE DATA(PDF) AND CREATE EMBEDDINGS AND STORE THEM IN VECTOR STORE"
      ],
      "metadata": {
        "id": "GV5VwaxDzLgh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "pdf_filename = \"/content/extended_data.pdf\"\n",
        "# print(f\"Processing PDF file: {pdf_filename}\")\n",
        "\n",
        "# Load the PDF document(s)\n",
        "loader = PDFPlumberLoader(pdf_filename)\n",
        "raw_docs = loader.load()  # returns a list of Document objects\n",
        "\n",
        "# Combine text from all pages\n",
        "combined_text = \"\\n\".join([doc.page_content for doc in raw_docs])\n",
        "print(\"Raw PDF text loaded. Preview:\")\n",
        "print(combined_text[:500])\n",
        "\n",
        "def extract_all_json_arrays(text):\n",
        "    \"\"\"\n",
        "    Extracts all balanced JSON arrays from the text.\n",
        "    Returns a list of JSON array strings.\n",
        "    \"\"\"\n",
        "    arrays = []\n",
        "    start = 0\n",
        "    while True:\n",
        "        start = text.find('[', start)\n",
        "        if start == -1:\n",
        "            break\n",
        "        count = 0\n",
        "        end = -1\n",
        "        for i, char in enumerate(text[start:], start):\n",
        "            if char == '[':\n",
        "                count += 1\n",
        "            elif char == ']':\n",
        "                count -= 1\n",
        "                if count == 0:\n",
        "                    end = i\n",
        "                    break\n",
        "        if end != -1:\n",
        "            arrays.append(text[start:end+1])\n",
        "            start = end + 1\n",
        "        else:\n",
        "            break\n",
        "    return arrays\n",
        "\n",
        "# Clean text by removing problematic control characters\n",
        "clean_text = re.sub(r'[\\x00-\\x1F\\x7F]', '', combined_text)\n",
        "\n",
        "# Extract all JSON array substrings\n",
        "json_arrays = extract_all_json_arrays(clean_text)\n",
        "all_qa = []\n",
        "for arr in json_arrays:\n",
        "    try:\n",
        "        data = json.loads(arr)\n",
        "        if isinstance(data, list):\n",
        "            all_qa.extend(data)\n",
        "    except json.JSONDecodeError as e:\n",
        "        print(\"Error parsing an array:\", e)\n",
        "\n",
        "print(f\"Total Q&A pairs found: {len(all_qa)}\")\n",
        "\n",
        "# Create Document objects where each Q&A pair is preserved as one chunk.\n",
        "qa_documents = []\n",
        "for qa in all_qa:\n",
        "    q = qa.get(\"question\", \"\").strip()\n",
        "    a = qa.get(\"answer\", \"\").strip()\n",
        "    if q and a:\n",
        "        # Format each Q&A pair so the Document contains one Q&A.\n",
        "        qa_text = f\"Question: {q}\\nAnswer: {a}\"\n",
        "        qa_documents.append(Document(page_content=qa_text))\n",
        "print(f\"Created {len(qa_documents)} Document objects from Q&A data.\")\n",
        "\n",
        "# Create an embeddings instance using a CPU-friendly model\n",
        "embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
        "\n",
        "# Create an in-memory vector store and add the Q&A documents\n",
        "vectorstore = InMemoryVectorStore(embedding=embeddings)\n",
        "if qa_documents:\n",
        "    vectorstore.add_documents(qa_documents)\n",
        "    print(\"Documents added to the vector store.\")\n",
        "else:\n",
        "    print(\"No Q&A documents to add.\")\n",
        "\n"
      ],
      "metadata": {
        "id": "aaXD_livGi4z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TEST THE RETRIEVAL TO GET INSIGHTS"
      ],
      "metadata": {
        "id": "j2zuQ1Rlzq5X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Test retrieval: get the top 3 Q&A pairs for a sample query.\n",
        "query = \"sports in kiet collge\"\n",
        "retrieved_with_scores = vectorstore.similarity_search_with_score(query, k=5)\n",
        "\n",
        "print(\"\\n----- Retrieved Top 3 Q&A Pairs -----\")\n",
        "for i, (doc, score) in enumerate(retrieved_with_scores, 1):\n",
        "    print(f\"Result {i}:\")\n",
        "    print(\"Similarity Score:\", score)\n",
        "    print(doc.page_content)\n",
        "    print(\"-\" * 40)"
      ],
      "metadata": {
        "id": "jX4fTq_UGG98"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "IF YOU THINK RETRIEVED DATA IS GOOD ENOUGH SAVE THE EMBEDDINGS"
      ],
      "metadata": {
        "id": "8vppWJfez-rE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "# Create a list to hold the embeddings data\n",
        "embeddings_data = []\n",
        "for doc in qa_documents:\n",
        "    # Compute the embedding vector for the document's text using embed_query\n",
        "    vector = embeddings.embed_query(doc.page_content)\n",
        "    embeddings_data.append({\n",
        "        \"document\": doc.page_content,\n",
        "        \"embedding\": vector\n",
        "    })\n",
        "\n",
        "# Save the embeddings data to a JSON file\n",
        "with open(\"embeddings.json\", \"w\") as f:\n",
        "    json.dump(embeddings_data, f)\n",
        "\n",
        "# Download the JSON file\n",
        "files.download(\"embeddings.json\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "0gf48XvPY4CB",
        "outputId": "9b91057d-476e-4644-b813-de02c1a1a925"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_d3309b23-59c2-4344-9245-fcffa680ee1b\", \"embeddings.json\", 2501193)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}